# Block all crawlers on staging environment
# For production, this file should be replaced with proper rules

User-agent: *
Disallow: /

# Specifically block major search engines
User-agent: Googlebot
Disallow: /

User-agent: Bingbot
Disallow: /

User-agent: Slurp
Disallow: /

User-agent: DuckDuckBot
Disallow: /

User-agent: Baiduspider
Disallow: /

User-agent: YandexBot
Disallow: /

# Block archiving bots
User-agent: ia_archiver
Disallow: /

User-agent: Wayback Machine
Disallow: /

# Block social media crawlers
User-agent: facebookexternalhit
Disallow: /

User-agent: Twitterbot
Disallow: /

User-agent: LinkedInBot
Disallow: /

User-agent: WhatsApp
Disallow: /

User-agent: Applebot
Disallow: /

# No sitemap for staging
Sitemap: